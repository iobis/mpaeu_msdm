% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/split_dataset.R
\name{split_dataset}
\alias{split_dataset}
\title{Split single file parquet dataset into multiple files}
\usage{
split_dataset(
  local_file,
  database_name,
  grouping_key,
  sel_keys = NULL,
  change_key = NULL,
  sel_columns = NULL,
  run_in_batches = FALSE,
  batch_size = NULL
)
}
\arguments{
\item{local_file}{path to the local parquet dataset file/folder.}

\item{database_name}{the name of the original database. Will be used as
a grouping key in the final folder format.}

\item{grouping_key}{\code{character} indicating the key used for spliting
(e.g. AphiaID, for OBIS datasets)}

\item{sel_keys}{an optional \code{vector} containing a set of keys for which
you want the split. This is specially relevant if you have a full export and
want the split for just a set of species. Note that if keys are substituted,
\code{sel_keys} should reflect the new key, not the older one.}

\item{change_key}{an optional \code{data.frame} containing two columns (key, new_key)
for changing the final grouping key (see details).}

\item{sel_columns}{an optional character vector of column names which should be
selected for the final files. Should include at least the grouping key.}

\item{run_in_batches}{if \code{sel_keys} are supplied and this option is \code{TRUE},
then the dataset is split in several batches according to the \code{batch_size}. The function
loop through the batches to save all groups. This option is strongly recommended if
the dataset is huge, as the split by Arrow function can fail in those cases.}

\item{batch_size}{an optional size for the batch. If it's too big, then the
function may still fail. If too small, then it may take too much time to run. If \code{NULL},
the default of 100 is used.}
}
\value{
saved files
}
\description{
Split single file parquet dataset into multiple files
}
\details{
If you have a single parquet file or a parquet dataset that have a grouping key
and want to split in the standard format used in the project, then it's more
recommended to use this function then the \code{\link[=mp_get_local]{mp_get_local()}}. This function
use the base Arrow capability to split the file, so it's really fast.
\subsection{How Files are saved?}{

Files will be saved on "data/species" (if the folder does not exist on the
working directory it will be created) and then a folder for each species,
using the code key=AphiaID. Files are saved with the date of generation.

So, for a species with AphiaID 12345, from OBIS,
downloaded (or processed) on 2023-01-05, a folder would be structured as that:

data/species/key=12345/obis_20230105.parquet
}

\subsection{Changing the key}{

The dataset will be split by the grouping key. However, sometimes you want to consistently
save all the files using a single identifier. For example, GBIF files will be saved
by specieskey (or other grouping), but you may want to identify all by the AphiaID.
In that case you can supplly the optional \code{change_key} argument which should be
a \code{data.frame} with two columns: the original grouping key (name "key") and the
equivalent new key (named "new_key"). Files will be renamed according to the new key.
In this case, if you want to also select just part of the dataset, the \code{sel_keys}
should be based on the "new_key" column, as the filter is performed after the key
substitution.
}
}
\examples{
\dontrun{
split_dataset("local_dataset.parquet", "obis", "AphiaID")
}
}
