% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mp_standardize.R
\name{mp_standardize}
\alias{mp_standardize}
\title{Standardize occurrence data for SDMs}
\usage{
mp_standardize(
  species,
  species_list,
  sdm_base,
  species_folder = "data/raw",
  species_outfolder = "data/species",
  geo_out = TRUE,
  env_out = TRUE,
  remove_land = TRUE,
  narm_out = TRUE,
  add_fao = TRUE,
  fao_areas = "data/fao_areas.parquet",
  verbose = TRUE
)
}
\arguments{
\item{species}{the AphiaID for the species}

\item{sdm_base}{a base \code{SpatRaster} in the target resolution. You can
supply one of the environmental layers that you will use (same extent and
resolution planned for the SDM)}

\item{species_folder}{the folder where the species data is located (i.e. the
OBIS and GBIF full exports)}

\item{species_outfolder}{folder to output the files}

\item{geo_out}{if \code{TRUE} assess geographical outliers. Note that at least 5 records are necessary
for any outlier removal procedure (either geographical or environmental)}

\item{env_out}{if \code{TRUE} assess environmental outliers}

\item{remove_land}{if \code{TRUE} remove points from land. If \code{sdm_base}
is supplied, will use it as reference. Otherwise, will use the
\code{\link[obistools:check_onland]{obistools::check_onland()}} function}

\item{narm_out}{if \code{TRUE}, then the function
will not only remove the outliers, but also any NA value that there is (cells
for which no distance or environmental information was found)}

\item{add_fao}{if \code{TRUE}, add information from FishBase and SeaLifeBase of where
the species is native, endemic or introduced, using FAO areas}

\item{fao_areas}{path to parquet file with FAO areas information (see \code{\link[rfishbase:fb_tbl]{rfishbase::fb_tbl()}})}
}
\value{
saved files (see details)
}
\description{
Standardize occurrence data for SDMs
}
\details{
This function aims to standardize (i.e. prepare) the occurrence data
for use on the SDM. It does not have much flexibility in terms of arguments -
and this is in purpose, as the aim is to produce one particular configuration
for the SDMs. However, all the underlying functions are available for the user
in the package, so you can assembly your own 'standardize' function.

The function will perform the following steps:
\enumerate{
\item Open the most recent files from both OBIS and GBIF (those that are available)
\item It will then verify if there are duplicated records, using GeoHash (resolution of 6)
and the year of the record.
\item If \code{remove_land} is \code{TRUE}, will remove points from land
\item If outlier removal methods were set as \code{TRUE}, it will tag (not remove)
the outliers (using limit of removal as 0.05\%, see \code{\link[=outqc_geo]{outqc_geo()}} or \code{\link[=outqc_env]{outqc_env()}} for more details).
Then, this file is saved, following this pattern:
}

species_folder/key=\verb{SPECIES KEY}/date=\verb{CURRENT DATE IN YMD FORMAT}/ftype=dupclean/spdata0.parquet

If you set prepare_sdm (there is no reason to not leave this as \code{TRUE}), then:
\enumerate{
\item The function will remove the outliers based on MAD (for environmental will
consider only bathymetry). If \code{out_from_cell = TRUE}, this will be done
based on a per-cell version of the dataset. This is recommended, because if you have
a very dense region, in terms of points, this can influence the outlier removal procedure.
Each dataset is converted to 1 per cell, then the equivalent cells in the aggregated
distance layer are retrieved (for the whole set of data), duplicated points are removed and outliers are detected.
Any duplicated point (falling on the same point then other dataset) receives the same outlier status than its
duplicate.
\item Then it will try to set one dataset to be used
as independent evaluation data. First it will calculate the standard distance
to assess how spread points are (spreadness in the rest of the doc)
and then the number of points in each dataset
(this considering the converted data to 1 per cell). After that it will
filter and remove those datasets with less than 10 records. If more than 1 dataset is
still available, it will order the datasets by their spreadness (high to low)
and remove the 50\% with lowest spreadness. Then it will get the dataset with
the lowest impact in the total number of records to be used as an evaluation
dataset.
\item It will convert both the evaluation and the fitting dataset to 1 per cell and save.
}

It will save one single file following this pattern:

species_folder/key=\verb{SPECIES KEY}/date=\verb{CURRENT DATE IN YMD FORMAT}/ftype=stdpts/spdata0.parquet

This file will have the following columns:
\itemize{
\item decimalLongitude
\item decimalLatitude
\item data_type: one of "fit_points" and "eval_points". The last will only be available if the
function was able to retrieve an evaluation dataset. To use the data for SDMs
you should then filter it and get a dataset for fiting the model (fit_points) and
to evaluate the final model (eval_points).
\item dataset_sel: only for eval_points, the dataset that was used to retrieve the evaluation points
\item taxonID: the AphiaID, for control
\item species: scientificName, for control
}

Aggregate resolution used in the outlier removal process is 0.8 (see \code{\link[=outqc_geo]{outqc_geo()}})
}
\section{Important note}{
Even if the function succeed in setting one dataset apart for evaluation, note that the selected
dataset may be important to model fitting! This is specially true if there was a small number of datasets.
As explained, if after removing those datasets with less than 10 records there are at least 2 datasets,
the function will proceed and select the 50\% with highest spreadness for the next step. Thus, in this case
the one dataset with high spreadness will be chosen and the one with lower spreadness will be used to
model fitting.

We recommend that you do one additional step of checking before using the dataset. For example, in this work
we checked, before the SDM:
\enumerate{
\item If the number of records in the evaluation dataset was higher than in the fitting one, and;
\item The inclusion of the evaluation dataset increased our coverage (number of TOTAL per cell records and
spreadness).
}

If this was the case, the evaluation dataset was incorporated in fitting (points were converted again
to 1 per cell, as some points could overlap).
}

\examples{
\dontrun{
mp_standardize(21510)
}
}
